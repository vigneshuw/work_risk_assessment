{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-23T18:49:55.729579Z",
     "start_time": "2023-10-23T18:49:54.039186Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os \n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lib import feature_extraction as fe\n",
    "from lib import models"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Loader\n",
    "\n",
    "- Selecting and loading the required data instances\n",
    "- Loading all data from the LiftingAssessment Task"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e157958657110977"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Main data path\n",
    "data_path = os.path.join(os.getcwd(), \"data\")\n",
    "# Selecting Task-2\n",
    "weight_lifting = os.path.join(data_path, \"LiftingAssessment\")\n",
    "# Get all the \".csv\" files\n",
    "all_parsed_files = glob.glob(\"**/*.csv\", root_dir=weight_lifting, recursive=True)\n",
    "\n",
    "# Load the data\n",
    "loaded_data = {}\n",
    "for file_path in all_parsed_files:\n",
    "    # Full path to file\n",
    "    full_path = os.path.join(weight_lifting, file_path)\n",
    "\n",
    "    # Load the time of DAQ\n",
    "    with open(full_path, \"r\") as file_handle:\n",
    "        daq_time = file_handle.readline()\n",
    "        daq_time = daq_time.split(\" \")[-1]\n",
    "        daq_time = int(daq_time[0:-2])\n",
    "    # Read the csv\n",
    "    df = pd.read_csv(full_path, header=\"infer\", skiprows=1)\n",
    "\n",
    "    # Store data\n",
    "    loaded_data[full_path] = {\n",
    "        \"daq_time\": daq_time,\n",
    "        \"df\": df\n",
    "    }\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T18:49:58.736652Z",
     "start_time": "2023-10-23T18:49:55.734182Z"
    }
   },
   "id": "548ed1087dbecda"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files loaded - 600\n"
     ]
    }
   ],
   "source": [
    "# Print the counts\n",
    "print(f\"Total number of files loaded - {len(loaded_data.keys())}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T18:49:58.742865Z",
     "start_time": "2023-10-23T18:49:58.737109Z"
    }
   },
   "id": "4991ea2c8b528d58"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Group by features\n",
    "box_types = [\"Crate\", \"CardboardBox\"]\n",
    "weight_levels = [\"W2\", \"W5\", \"W10\", \"W15\", \"W30\"]\n",
    "labelled_data = {}\n",
    "for box_instance in box_types:\n",
    "    for weight_instance in weight_levels:\n",
    "        labelled_data[box_instance + \"-\" + weight_instance] = []\n",
    "\n",
    "for file_id in loaded_data.keys():\n",
    "    box_instance = file_id.split(os.sep)[-4]\n",
    "    weight_instance = file_id.split(os.sep)[-3]\n",
    "    labelled_data[box_instance + \"-\" + weight_instance].append(file_id)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T18:50:00.093558Z",
     "start_time": "2023-10-23T18:50:00.087403Z"
    }
   },
   "id": "987f91d9809a390e"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the class - Crate-W2, total number of items are 60\n",
      "For the class - Crate-W5, total number of items are 60\n",
      "For the class - Crate-W10, total number of items are 60\n",
      "For the class - Crate-W15, total number of items are 60\n",
      "For the class - Crate-W30, total number of items are 60\n",
      "For the class - CardboardBox-W2, total number of items are 60\n",
      "For the class - CardboardBox-W5, total number of items are 60\n",
      "For the class - CardboardBox-W10, total number of items are 60\n",
      "For the class - CardboardBox-W15, total number of items are 60\n",
      "For the class - CardboardBox-W30, total number of items are 60\n"
     ]
    }
   ],
   "source": [
    "# Print number of items within each group\n",
    "for class_instance in labelled_data.keys():\n",
    "    print(f\"For the class - {class_instance}, total number of items are {len(labelled_data[class_instance])}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T18:50:00.693797Z",
     "start_time": "2023-10-23T18:50:00.686841Z"
    }
   },
   "id": "706850e404d09433"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Rate for DAQSentinel01 with mean 396.8 and std of 13.25\n",
      "Sampling Rate for DAQSentinel02 with mean 388.31 and std of 12.9\n",
      "Sampling Rate for DAQSentinel03 with mean 390.16 and std of 13.0\n"
     ]
    }
   ],
   "source": [
    "sentinels_samplingRate = {\"DAQSentinel01\": [],\n",
    "                          \"DAQSentinel02\": [],\n",
    "                          \"DAQSentinel03\": []}\n",
    "sampling_rates = {}\n",
    "for file_path, data in loaded_data.items():\n",
    "    # Choose the right sentinel\n",
    "    sentinel = file_path.split(\"/\")[-1].split(\"_\")[0]\n",
    "\n",
    "    # Determine sampling rate\n",
    "    total_time = data[\"daq_time\"]\n",
    "    samples = data[\"df\"].shape[0]\n",
    "    sentinels_samplingRate[sentinel].append(samples / total_time)\n",
    "\n",
    "for sentinel in sentinels_samplingRate.keys():\n",
    "    print(\"Sampling Rate for \" + sentinel + \" with mean \" + str(round(np.mean(sentinels_samplingRate[sentinel]), 2)) +\n",
    "          \" and std of \" + str(round(np.std(sentinels_samplingRate[sentinel]), 2)))\n",
    "\n",
    "    # Get the mean sampling rate\n",
    "    sampling_rates[sentinel] = round(np.mean(sentinels_samplingRate[sentinel]), 2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T18:50:01.920111Z",
     "start_time": "2023-10-23T18:50:01.914464Z"
    }
   },
   "id": "e93041dd51c0727e"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class_combined_dfs = {}\n",
    "sentinels = [\"DAQSentinel01\", \"DAQSentinel02\", \"DAQSentinel03\"]\n",
    "\n",
    "# Group dataframes together\n",
    "for class_instance in labelled_data.keys():\n",
    "    # Differentiate by Sentinels\n",
    "    class_combined_dfs[class_instance] = {}\n",
    "    \n",
    "    # Sentinels data instance counters\n",
    "    counters = {}\n",
    "    \n",
    "    # Go through each file\n",
    "    for file_id in labelled_data[class_instance]:\n",
    "        # Get the sentinel name\n",
    "        sentinel = file_id.split(os.sep)[-1].split(\"_\")[0]\n",
    "        \n",
    "        # Get the dataframe\n",
    "        df = loaded_data[file_id][\"df\"].copy(deep=True)\n",
    "        # Remove the starting and ending data instances\n",
    "        df = df.iloc[int(4 * sampling_rates[sentinel]):int(df.shape[0] - (4 * sampling_rates[sentinel]))]\n",
    "        \n",
    "        if sentinel in list(class_combined_dfs[class_instance].keys()):\n",
    "            class_combined_dfs[class_instance][sentinel] = pd.concat([class_combined_dfs[class_instance][sentinel], df], ignore_index=True, copy=True)\n",
    "            counters[sentinel] += 1\n",
    "        else:\n",
    "            class_combined_dfs[class_instance][sentinel] = df\n",
    "            counters[sentinel] = 1\n",
    "            \n",
    "    # Assert at the end of every class\n",
    "    for s in counters.values():\n",
    "        assert s == 20, \"Each sentinel should add upto 20 counts for two individuals\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T18:50:05.878339Z",
     "start_time": "2023-10-23T18:50:05.713882Z"
    }
   },
   "id": "3ad99416766bd0fa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Segmentation\n",
    "\n",
    "- 1 second segments with 250ms overlap between segments"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f17f2474da1dfadb"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# To ensure order\n",
    "data_cols_considered = [\"acc-X\", \"acc-Y\", \"acc-Z\", \"gyr-X\", \"gyr-Y\", \"gyr-Z\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T18:50:06.928123Z",
     "start_time": "2023-10-23T18:50:06.926172Z"
    }
   },
   "id": "c986812ec6404f2"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def segment_data(data_array: np.array, segment_window: float, overlap: float, sampling_rate: float):\n",
    "    \n",
    "    window_size = int(segment_window * sampling_rate)\n",
    "    starting_points = np.arange(0, data_array.shape[0], int(window_size * (1 - overlap))).astype(\"uint32\")\n",
    "    \n",
    "    data_segments = list()\n",
    "    for starting_index in starting_points:\n",
    "        if(starting_index + window_size) < data_array.shape[0]:\n",
    "            data_segments.append(\n",
    "                data_array[starting_index:starting_index + window_size, ...])\n",
    "            \n",
    "    return np.array(data_segments)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T18:50:07.354901Z",
     "start_time": "2023-10-23T18:50:07.349656Z"
    }
   },
   "id": "77936a6bb3946ae7"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Segment the data\n",
    "sentinel_segmented_data = {}\n",
    "for class_instance in class_combined_dfs.keys():\n",
    "    sentinel_segmented_data[class_instance] = {}\n",
    "    for sentinel in class_combined_dfs[class_instance].keys():\n",
    "        sentinel_segmented_data[class_instance][sentinel] = segment_data(class_combined_dfs[class_instance][sentinel][data_cols_considered].to_numpy(), 1.0, 0.75, sampling_rates[sentinel])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T18:50:08.143265Z",
     "start_time": "2023-10-23T18:50:08.065963Z"
    }
   },
   "id": "92ea59ad03c45a45"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Extraction\n",
    "\n",
    "Extraction key features from the acceleration data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d4852cb67bc3460"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Time-frequency features\n",
    "\n",
    "Extracting the following features, a total of 17 features\n",
    "\n",
    "- Time domain\n",
    "- Frequency domain\n",
    "- Time-frequency domain"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e0df0cfda2c4426"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "features_extracted_data = {}\n",
    "for class_instance in sentinel_segmented_data.keys():\n",
    "    features_extracted_data[class_instance] = {}\n",
    "    for sentinel in sentinel_segmented_data[class_instance].keys():\n",
    "        data = sentinel_segmented_data[class_instance][sentinel]\n",
    "        \n",
    "        # Select arguments based on sentinel\n",
    "        freq_args = [{\"axis\": 0}, {\"axis\": 0}, {\"axis\": 0, \"nperseg\": 200, \"noverlap\": 100, \"fs\": sampling_rates[sentinel]}]\n",
    "        freq_time_args = [{\"wavelet\": \"db1\"}, {\"wavelet\": \"db1\"}, {\"wavelet\": \"db1\"}]\n",
    "        \n",
    "        # Apply transformation to every data row\n",
    "        for index, row in enumerate(data):\n",
    "            computed_segments_sensors = []\n",
    "            for i in range(data.shape[-1]):\n",
    "                # apply the transformation\n",
    "                computed_segments_sensors += fe.compute_all_features(row[:, i], freq_args=freq_args, freq_time_args=freq_time_args)\n",
    "            \n",
    "            data_array = np.array(computed_segments_sensors).T\n",
    "            if index == 0:\n",
    "                features_extracted_data[class_instance][sentinel] = copy.deepcopy(data_array[np.newaxis, ...])\n",
    "            else:\n",
    "                features_extracted_data[class_instance][sentinel] = np.append(features_extracted_data[class_instance][sentinel], copy.deepcopy(data_array[np.newaxis, ...]), axis=0)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T18:52:36.468419Z",
     "start_time": "2023-10-23T18:51:50.420332Z"
    }
   },
   "id": "e1b3009c41949794"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Development\n",
    "\n",
    "- Choose among the 10 available models\n",
    "- set the parameters appropriately\n",
    "- Train the model and get the metrics\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f08b725a7da7832"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"LogisticRegression\" : {\"class_weight\": \"balanced\", \"max_iter\": 5000, \"n_jobs\": 4},\n",
    "    \"DecisionTreeClassifier\": {\"min_samples_split\": 100},\n",
    "    \"KNeighborsClassifier\": {\"n_neighbors\": 10},\n",
    "    \"SVC\": {\"kernel\": \"rbf\", \"tol\":1e-7},\n",
    "    \"BaggingClassifier\": {\"n_estimators\": 50},\n",
    "    \"RandomForestClassifier\": {\"n_estimators\": 100, \"min_samples_split\": 100, \"class_weight\": \"balanced\"},\n",
    "}\n",
    "\n",
    "# NIOSH labels\n",
    "labels = {\n",
    "    \"Crate-W2\": 0,\n",
    "    \"Crate-W5\": 0,\n",
    "    \"Crate-W10\": 0,\n",
    "    \"Crate-W15\": 1,\n",
    "    \"Crate-W30\": 1,\n",
    "    \"CardboardBox-W2\": 0,\n",
    "    \"CardboardBox-W5\": 0,\n",
    "    \"CardboardBox-W10\": 0,\n",
    "    \"CardboardBox-W15\": 1,\n",
    "    \"CardboardBox-W30\": 1,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T18:52:40.922654Z",
     "start_time": "2023-10-23T18:52:40.917332Z"
    }
   },
   "id": "a63f55f7258bd004"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Individual Sentinels\n",
    "\n",
    "Model development by considering one Sentinel at a time\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f15a4bcfc74055c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Choose the sentinel for model training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "813f463ae2a75c59"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "sentinel = \"DAQSentinel02\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T18:52:50.133111Z",
     "start_time": "2023-10-23T18:52:50.125173Z"
    }
   },
   "id": "a83a59efcf3859e8"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X-train is (3611, 102)\n",
      "Shape of y-train is (3611,)\n"
     ]
    }
   ],
   "source": [
    "# Construct training data and labels\n",
    "for index, class_instance in enumerate(features_extracted_data.keys()):\n",
    "    # Select sentinel\n",
    "    if index == 0:\n",
    "        X_train = features_extracted_data[class_instance][sentinel]\n",
    "        y_train = np.array([labels[class_instance]] * features_extracted_data[class_instance][sentinel].shape[0])[:, np.newaxis]\n",
    "    else:\n",
    "        X_train = np.append(X_train, features_extracted_data[class_instance][sentinel], axis=0)\n",
    "        y_train = np.append(y_train, np.array([labels[class_instance]] * features_extracted_data[class_instance][sentinel].shape[0])[:, np.newaxis], axis=0)\n",
    "        \n",
    "# Print results\n",
    "print(f\"Shape of X-train is {X_train.shape}\")\n",
    "y_train = y_train.squeeze(axis=-1)\n",
    "print(f\"Shape of y-train is {y_train.shape}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T18:52:50.680351Z",
     "start_time": "2023-10-23T18:52:50.668817Z"
    }
   },
   "id": "6a30e930524114f2"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 9\r"
     ]
    }
   ],
   "source": [
    "# Create models repo\n",
    "models_repo = models.Models()\n",
    "# Initialize\n",
    "models_repo.create_models(model_params)\n",
    "\n",
    "# 10-fold CV\n",
    "cv_results_summary = models_repo.train_models_cvfolds(X_train, y_train, summarize_results=True, standardize=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T18:55:11.713580Z",
     "start_time": "2023-10-23T18:53:28.921827Z"
    }
   },
   "id": "a770efcf0214ad3f"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Model names\n",
    "model_association = [\n",
    "    \"LogisticRegression\",\n",
    "    \"DecisionTreeClassifier\",\n",
    "    \"KNeighborsClassifier\",\n",
    "    \"SVC\",\n",
    "    \"BaggingClassifier\",\n",
    "    \"RandomForestClassifier\"\n",
    "]\n",
    "\n",
    "# Make a copy\n",
    "temp = copy.deepcopy(cv_results_summary)\n",
    "\n",
    "for index, model_name in enumerate(model_association):\n",
    "\n",
    "    temp[model_name].columns = pd.MultiIndex.from_product([[model_name], temp[model_name].columns])\n",
    "    # Append columns\n",
    "    if index == 0:\n",
    "        combined_cv_results = temp[model_name]\n",
    "    else:\n",
    "        combined_cv_results = pd.concat([combined_cv_results, temp[model_name]], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T18:55:17.400946Z",
     "start_time": "2023-10-23T18:55:17.398241Z"
    }
   },
   "id": "d6c956ace46df8d4"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "                        LogisticRegression                                \\\n                                   average       std       min       max   \naccuracy_score                    0.708946  0.019758  0.675900  0.745152   \nbalanced_accuracy_score           0.701476  0.020547  0.666553  0.734963   \nf1_score                          0.639207  0.024102  0.597938  0.676056   \nrecall_score                      0.668849  0.027448  0.625899  0.697842   \nprecision_score                   0.612288  0.024300  0.572368  0.662069   \n\n                              DecisionTreeClassifier                      \\\n                        count                average       std       min   \naccuracy_score             10               0.702319  0.034114  0.629834   \nbalanced_accuracy_score    10               0.672280  0.039396  0.582111   \nf1_score                   10               0.581923  0.059863  0.436975   \nrecall_score               10               0.541043  0.072706  0.371429   \nprecision_score            10               0.632817  0.051928  0.530612   \n\n                                         ... BaggingClassifier            \\\n                              max count  ...           average       std   \naccuracy_score           0.745152    10  ...          0.813074  0.013607   \nbalanced_accuracy_score  0.724204    10  ...          0.780330  0.017517   \nf1_score                 0.656716    10  ...          0.723828  0.025219   \nrecall_score             0.633094    10  ...          0.637276  0.041655   \nprecision_score          0.682171    10  ...          0.840636  0.028961   \n\n                                                  RandomForestClassifier  \\\n                              min       max count                average   \naccuracy_score           0.797784  0.836565    10               0.759900   \nbalanced_accuracy_score  0.759620  0.810633    10               0.747502   \nf1_score                 0.689956  0.766798    10               0.689544   \nrecall_score             0.564286  0.705036    10               0.693299   \nprecision_score          0.805556  0.887640    10               0.687094   \n\n                                                             \n                              std       min       max count  \naccuracy_score           0.029956  0.722992  0.803324    10  \nbalanced_accuracy_score  0.033265  0.707564  0.794365    10  \nf1_score                 0.041327  0.633962  0.747405    10  \nrecall_score             0.054842  0.604317  0.776978    10  \nprecision_score          0.036942  0.629139  0.739437    10  \n\n[5 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"5\" halign=\"left\">LogisticRegression</th>\n      <th colspan=\"5\" halign=\"left\">DecisionTreeClassifier</th>\n      <th>...</th>\n      <th colspan=\"5\" halign=\"left\">BaggingClassifier</th>\n      <th colspan=\"5\" halign=\"left\">RandomForestClassifier</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>average</th>\n      <th>std</th>\n      <th>min</th>\n      <th>max</th>\n      <th>count</th>\n      <th>average</th>\n      <th>std</th>\n      <th>min</th>\n      <th>max</th>\n      <th>count</th>\n      <th>...</th>\n      <th>average</th>\n      <th>std</th>\n      <th>min</th>\n      <th>max</th>\n      <th>count</th>\n      <th>average</th>\n      <th>std</th>\n      <th>min</th>\n      <th>max</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>accuracy_score</th>\n      <td>0.708946</td>\n      <td>0.019758</td>\n      <td>0.675900</td>\n      <td>0.745152</td>\n      <td>10</td>\n      <td>0.702319</td>\n      <td>0.034114</td>\n      <td>0.629834</td>\n      <td>0.745152</td>\n      <td>10</td>\n      <td>...</td>\n      <td>0.813074</td>\n      <td>0.013607</td>\n      <td>0.797784</td>\n      <td>0.836565</td>\n      <td>10</td>\n      <td>0.759900</td>\n      <td>0.029956</td>\n      <td>0.722992</td>\n      <td>0.803324</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>balanced_accuracy_score</th>\n      <td>0.701476</td>\n      <td>0.020547</td>\n      <td>0.666553</td>\n      <td>0.734963</td>\n      <td>10</td>\n      <td>0.672280</td>\n      <td>0.039396</td>\n      <td>0.582111</td>\n      <td>0.724204</td>\n      <td>10</td>\n      <td>...</td>\n      <td>0.780330</td>\n      <td>0.017517</td>\n      <td>0.759620</td>\n      <td>0.810633</td>\n      <td>10</td>\n      <td>0.747502</td>\n      <td>0.033265</td>\n      <td>0.707564</td>\n      <td>0.794365</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>f1_score</th>\n      <td>0.639207</td>\n      <td>0.024102</td>\n      <td>0.597938</td>\n      <td>0.676056</td>\n      <td>10</td>\n      <td>0.581923</td>\n      <td>0.059863</td>\n      <td>0.436975</td>\n      <td>0.656716</td>\n      <td>10</td>\n      <td>...</td>\n      <td>0.723828</td>\n      <td>0.025219</td>\n      <td>0.689956</td>\n      <td>0.766798</td>\n      <td>10</td>\n      <td>0.689544</td>\n      <td>0.041327</td>\n      <td>0.633962</td>\n      <td>0.747405</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>recall_score</th>\n      <td>0.668849</td>\n      <td>0.027448</td>\n      <td>0.625899</td>\n      <td>0.697842</td>\n      <td>10</td>\n      <td>0.541043</td>\n      <td>0.072706</td>\n      <td>0.371429</td>\n      <td>0.633094</td>\n      <td>10</td>\n      <td>...</td>\n      <td>0.637276</td>\n      <td>0.041655</td>\n      <td>0.564286</td>\n      <td>0.705036</td>\n      <td>10</td>\n      <td>0.693299</td>\n      <td>0.054842</td>\n      <td>0.604317</td>\n      <td>0.776978</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>precision_score</th>\n      <td>0.612288</td>\n      <td>0.024300</td>\n      <td>0.572368</td>\n      <td>0.662069</td>\n      <td>10</td>\n      <td>0.632817</td>\n      <td>0.051928</td>\n      <td>0.530612</td>\n      <td>0.682171</td>\n      <td>10</td>\n      <td>...</td>\n      <td>0.840636</td>\n      <td>0.028961</td>\n      <td>0.805556</td>\n      <td>0.887640</td>\n      <td>10</td>\n      <td>0.687094</td>\n      <td>0.036942</td>\n      <td>0.629139</td>\n      <td>0.739437</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_cv_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T18:55:18.156918Z",
     "start_time": "2023-10-23T18:55:18.141561Z"
    }
   },
   "id": "dd890a24c7c1dddd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## All Sentinels\n",
    "\n",
    "- Considering all Sentinels in the model training process"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25c5ef03b2050d97"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X-train is (3609, 306)\n",
      "Shape of y-train is (3609,)\n"
     ]
    }
   ],
   "source": [
    "# Construct training data and labels\n",
    "for index, class_instance in enumerate(features_extracted_data.keys()):\n",
    "    \n",
    "    # Find the sentinel with min samples\n",
    "    samples = []\n",
    "    for sentinel in sentinels:\n",
    "        samples.append(features_extracted_data[class_instance][sentinel].shape[0])\n",
    "    \n",
    "    min_samples = min(samples)\n",
    "\n",
    "    for index2, sentinel in enumerate(sentinels):\n",
    "        if index2 == 0:\n",
    "            sub_X_train = features_extracted_data[class_instance][sentinel][0:min_samples, ...]\n",
    "        else:\n",
    "            sub_X_train = np.concatenate((sub_X_train, features_extracted_data[class_instance][sentinel][0:min_samples, ...]), axis=-1)\n",
    "    \n",
    "    if index == 0:\n",
    "        X_train = copy.deepcopy(sub_X_train)\n",
    "        y_train = np.array([labels[class_instance]] * sub_X_train.shape[0])[:, np.newaxis]\n",
    "    else:\n",
    "        X_train = np.append(X_train, copy.deepcopy(sub_X_train), axis=0)\n",
    "        y_train = np.append(y_train, np.array([labels[class_instance]] * sub_X_train.shape[0])[:, np.newaxis], axis=0)\n",
    "        \n",
    "# Print results\n",
    "print(f\"Shape of X-train is {X_train.shape}\")\n",
    "y_train = y_train.squeeze(axis=-1)\n",
    "print(f\"Shape of y-train is {y_train.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T18:59:46.285975Z",
     "start_time": "2023-10-23T18:59:46.248632Z"
    }
   },
   "id": "cc183fa10caf3911"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 9\r"
     ]
    }
   ],
   "source": [
    "# Create models repo\n",
    "models_repo = models.Models()\n",
    "# Initialize\n",
    "models_repo.create_models(model_params)\n",
    "\n",
    "# 10-fold CV\n",
    "cv_results_summary = models_repo.train_models_cvfolds(X_train, y_train, summarize_results=True, standardize=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T19:04:12.765555Z",
     "start_time": "2023-10-23T18:59:47.702385Z"
    }
   },
   "id": "ef1eccc9d31a0cfc"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Model names\n",
    "model_association = [\n",
    "    \"LogisticRegression\",\n",
    "    \"DecisionTreeClassifier\",\n",
    "    \"KNeighborsClassifier\",\n",
    "    \"SVC\",\n",
    "    \"BaggingClassifier\",\n",
    "    \"RandomForestClassifier\"\n",
    "]\n",
    "\n",
    "# Make a copy\n",
    "temp = copy.deepcopy(cv_results_summary)\n",
    "\n",
    "for index, model_name in enumerate(model_association):\n",
    "\n",
    "    temp[model_name].columns = pd.MultiIndex.from_product([[model_name], temp[model_name].columns])\n",
    "    # Append columns\n",
    "    if index == 0:\n",
    "        combined_cv_results = temp[model_name]\n",
    "    else:\n",
    "        combined_cv_results = pd.concat([combined_cv_results, temp[model_name]], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T19:04:12.774906Z",
     "start_time": "2023-10-23T19:04:12.772068Z"
    }
   },
   "id": "afce8078219cbd26"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "                        LogisticRegression                                \\\n                                   average       std       min       max   \naccuracy_score                    0.778883  0.025549  0.750693  0.825485   \nbalanced_accuracy_score           0.771803  0.024416  0.740375  0.809693   \nf1_score                          0.720997  0.029514  0.681004  0.765799   \nrecall_score                      0.741007  0.034083  0.683453  0.791367   \nprecision_score                   0.703397  0.041945  0.662252  0.792308   \n\n                              DecisionTreeClassifier                      \\\n                        count                average       std       min   \naccuracy_score             10               0.753950  0.020868  0.706371   \nbalanced_accuracy_score    10               0.734324  0.022613  0.698052   \nf1_score                   10               0.669382  0.031160  0.609053   \nrecall_score               10               0.648921  0.056322  0.532374   \nprecision_score            10               0.695670  0.038022  0.609272   \n\n                                         ... BaggingClassifier            \\\n                              max count  ...           average       std   \naccuracy_score           0.778393    10  ...          0.881968  0.020080   \nbalanced_accuracy_score  0.770060    10  ...          0.860877  0.022292   \nf1_score                 0.718310    10  ...          0.833671  0.029228   \nrecall_score             0.733813    10  ...          0.769065  0.035155   \nprecision_score          0.761468    10  ...          0.910938  0.031113   \n\n                                                  RandomForestClassifier  \\\n                              min       max count                average   \naccuracy_score           0.858726  0.914127    10               0.832646   \nbalanced_accuracy_score  0.834030  0.897903    10               0.823731   \nf1_score                 0.798419  0.881226    10               0.782928   \nrecall_score             0.719424  0.827338    10               0.784892   \nprecision_score          0.872000  0.949153    10               0.782726   \n\n                                                             \n                              std       min       max count  \naccuracy_score           0.019766  0.806094  0.869806    10  \nbalanced_accuracy_score  0.022157  0.793490  0.864557    10  \nf1_score                 0.027232  0.745387  0.832740    10  \nrecall_score             0.044407  0.719424  0.841727    10  \nprecision_score          0.032308  0.744681  0.835938    10  \n\n[5 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"5\" halign=\"left\">LogisticRegression</th>\n      <th colspan=\"5\" halign=\"left\">DecisionTreeClassifier</th>\n      <th>...</th>\n      <th colspan=\"5\" halign=\"left\">BaggingClassifier</th>\n      <th colspan=\"5\" halign=\"left\">RandomForestClassifier</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>average</th>\n      <th>std</th>\n      <th>min</th>\n      <th>max</th>\n      <th>count</th>\n      <th>average</th>\n      <th>std</th>\n      <th>min</th>\n      <th>max</th>\n      <th>count</th>\n      <th>...</th>\n      <th>average</th>\n      <th>std</th>\n      <th>min</th>\n      <th>max</th>\n      <th>count</th>\n      <th>average</th>\n      <th>std</th>\n      <th>min</th>\n      <th>max</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>accuracy_score</th>\n      <td>0.778883</td>\n      <td>0.025549</td>\n      <td>0.750693</td>\n      <td>0.825485</td>\n      <td>10</td>\n      <td>0.753950</td>\n      <td>0.020868</td>\n      <td>0.706371</td>\n      <td>0.778393</td>\n      <td>10</td>\n      <td>...</td>\n      <td>0.881968</td>\n      <td>0.020080</td>\n      <td>0.858726</td>\n      <td>0.914127</td>\n      <td>10</td>\n      <td>0.832646</td>\n      <td>0.019766</td>\n      <td>0.806094</td>\n      <td>0.869806</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>balanced_accuracy_score</th>\n      <td>0.771803</td>\n      <td>0.024416</td>\n      <td>0.740375</td>\n      <td>0.809693</td>\n      <td>10</td>\n      <td>0.734324</td>\n      <td>0.022613</td>\n      <td>0.698052</td>\n      <td>0.770060</td>\n      <td>10</td>\n      <td>...</td>\n      <td>0.860877</td>\n      <td>0.022292</td>\n      <td>0.834030</td>\n      <td>0.897903</td>\n      <td>10</td>\n      <td>0.823731</td>\n      <td>0.022157</td>\n      <td>0.793490</td>\n      <td>0.864557</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>f1_score</th>\n      <td>0.720997</td>\n      <td>0.029514</td>\n      <td>0.681004</td>\n      <td>0.765799</td>\n      <td>10</td>\n      <td>0.669382</td>\n      <td>0.031160</td>\n      <td>0.609053</td>\n      <td>0.718310</td>\n      <td>10</td>\n      <td>...</td>\n      <td>0.833671</td>\n      <td>0.029228</td>\n      <td>0.798419</td>\n      <td>0.881226</td>\n      <td>10</td>\n      <td>0.782928</td>\n      <td>0.027232</td>\n      <td>0.745387</td>\n      <td>0.832740</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>recall_score</th>\n      <td>0.741007</td>\n      <td>0.034083</td>\n      <td>0.683453</td>\n      <td>0.791367</td>\n      <td>10</td>\n      <td>0.648921</td>\n      <td>0.056322</td>\n      <td>0.532374</td>\n      <td>0.733813</td>\n      <td>10</td>\n      <td>...</td>\n      <td>0.769065</td>\n      <td>0.035155</td>\n      <td>0.719424</td>\n      <td>0.827338</td>\n      <td>10</td>\n      <td>0.784892</td>\n      <td>0.044407</td>\n      <td>0.719424</td>\n      <td>0.841727</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>precision_score</th>\n      <td>0.703397</td>\n      <td>0.041945</td>\n      <td>0.662252</td>\n      <td>0.792308</td>\n      <td>10</td>\n      <td>0.695670</td>\n      <td>0.038022</td>\n      <td>0.609272</td>\n      <td>0.761468</td>\n      <td>10</td>\n      <td>...</td>\n      <td>0.910938</td>\n      <td>0.031113</td>\n      <td>0.872000</td>\n      <td>0.949153</td>\n      <td>10</td>\n      <td>0.782726</td>\n      <td>0.032308</td>\n      <td>0.744681</td>\n      <td>0.835938</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_cv_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T19:04:12.789839Z",
     "start_time": "2023-10-23T19:04:12.783409Z"
    }
   },
   "id": "7c6f8e677f01c9c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8c04907a65000676"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
